{"name": "PAI1_MLP_RFW", "model": "MLP_RWF(\n  (mlp): Sequential(\n    (layer_0): RWF()\n    (activation_0): SiLU()\n    (dropout_0): Dropout(p=0.2, inplace=False)\n    (layer_1): RWF()\n    (activation_1): SiLU()\n    (dropout_1): Dropout(p=0.2, inplace=False)\n    (layer_2): RWF()\n    (activation_2): SiLU()\n    (dropout_2): Dropout(p=0.2, inplace=False)\n    (layer_3): RWF()\n    (activation_3): SiLU()\n    (dropout_3): Dropout(p=0.2, inplace=False)\n    (layer_4): RWF()\n    (activation_4): SiLU()\n    (dropout_4): Dropout(p=0.2, inplace=False)\n    (layer_5): RWF()\n    (activation_5): SiLU()\n    (dropout_5): Dropout(p=0.2, inplace=False)\n    (layer_6): RWF()\n    (activation_6): SiLU()\n    (dropout_6): Dropout(p=0.2, inplace=False)\n    (layer_7): RWF()\n    (activation_7): SiLU()\n    (dropout_7): Dropout(p=0.2, inplace=False)\n    (layer_9): RWF()\n  )\n)", "epochs": 2000, "batchsize": 500, "optimizer": "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.99)\n    capturable: False\n    differentiable: False\n    eps: 1e-15\n    foreach: None\n    fused: None\n    initial_lr: 0.002203836177626117\n    lr: 0.002203836177626117\n    maximize: False\n    weight_decay: 0\n)", "scheduler": "{'step_size': 1721, 'gamma': 0.15913059595003437, 'base_lrs': [0.002203836177626117], 'last_epoch': 0, 'verbose': False, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [0.002203836177626117]}", "modules": "ComponentManager: {'Training Components': [{'Residual': {'ResidualLoss': {}}}, {'IC': [{'ICLoss': {}}]}], 'Validation Components': [{'Residual': {'ResidualLoss': {}}}, {'IC': [{'ICLoss': {}}]}]}", "additionalData": {"u_min": -0.21, "u_max": 0.0, "x_min": 0.0, "x_max": 1.0, "y_min": 0.0, "y_max": 1.0, "t_f": 10, "f_min": -3.0, "f_max": 0.0}}