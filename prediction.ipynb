{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = ['MLP', 'RWF', 'KAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_min, u_max = -0.21, 0.0\n",
    "x_min, x_max = 0.0, 1.0\n",
    "y_min, y_max = 0.0, 1.0\n",
    "t_f = 10\n",
    "f_min, f_max = -3.0, 0.0\n",
    "\n",
    "def hard_constraint(x_in, U_theta):\n",
    "    delta_u = u_max - u_min\n",
    "    delta_x = x_max - x_min\n",
    "    delta_y = y_max - y_min\n",
    "\n",
    "    X = x_in[0]\n",
    "    Y = x_in[1]\n",
    "    tau = x_in[-1]\n",
    "    x = X*delta_x + x_min\n",
    "    y = Y*delta_y + y_min\n",
    "    t = tau * t_f\n",
    "    u_theta = U_theta*delta_u + u_min\n",
    "\n",
    "    # se siamo sui bordi (qualsiasi dimensione) u=0, altrimenti abbiamo applicato una trasformazione non lineare a u_theta\n",
    "    u = u_theta * (x-x_min) *(x-x_max) * (y-y_min) * (y-y_max) * t\n",
    "    U = (u - u_min)/delta_u # forma esplicita: riga 72 in 73, poi righe 66-69 \n",
    "\n",
    "    # output normalizzato\n",
    "    return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191700\n"
     ]
    }
   ],
   "source": [
    "# Paths and setup\n",
    "csv_path = 'matlab/only_damp/space_time_points.csv'\n",
    "batch_size = 500\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert pandas Series to numpy arrays\n",
    "X = df['x'].to_numpy()\n",
    "Y = df['y'].to_numpy()\n",
    "T = df['t'].to_numpy()\n",
    "\n",
    "n_samples = len(X)\n",
    "print(n_samples)\n",
    "\n",
    "predictions = np.zeros(n_samples)\n",
    "\n",
    "# Prepare input data as tensor\n",
    "inputs = np.column_stack((X, Y, T))\n",
    "inputs = torch.FloatTensor(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_list:\n",
    "    for i in range(1, 7):\n",
    "        model_path = f\"training/{model_name}_{i}/model\"\n",
    "\n",
    "        output_path = f'matlab/only_damp/matlab_evaluations/predictions_csv_files/{model_name}_{i}'\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        model_files = glob.glob(os.path.join(model_path, \"model_*.pt\"))\n",
    "        if model_files:\n",
    "        # Extract numbers and find the highest one\n",
    "            latest_model = max(model_files, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "            print(\"Evaluating model in:\", latest_model)\n",
    "        else:\n",
    "            print(\"No model files found in the directory.\")\n",
    "\n",
    "        #model_path = latest_model\n",
    "\n",
    "        loaded_model = torch.load(latest_model)\n",
    "        loaded_model.eval()\n",
    "        \n",
    "        # Process in batches\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, n_samples):\n",
    "                # end_idx = min(i + batch_size, n_samples)  # Ensure we don't go past the array end\n",
    "                batch_inputs = inputs[i]\n",
    "                batch_outputs = loaded_model(batch_inputs)\n",
    "                pred = batch_outputs.cpu().numpy()\n",
    "                pred_denorm = (pred*(u_max - u_min)) + u_min\n",
    "                predictions[i] = pred_denorm # Only take the needed values\n",
    "            \n",
    "                print(pred_denorm)\n",
    "\n",
    "        # Formatting predictions for matlab use\n",
    "        reshaped_predictions = predictions.reshape(-1, 1917).T\n",
    "        np.savetxt(output_path + '/predictions.csv', reshaped_predictions, \n",
    "           delimiter=',', fmt='%.6f')  \n",
    "\n",
    "        print(f\"Predictions completed and saved to {output_path}\")\n",
    "        print(\"\\nSample predictions:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Print statistics about the predictions\n",
    "        print(\"\\nPrediction statistics:\")\n",
    "        print(f\"Mean: {predictions.mean():.4f}\")\n",
    "        print(f\"Std: {predictions.std():.4f}\")\n",
    "        print(f\"Min: {predictions.min():.4f}\")\n",
    "        print(f\"Max: {predictions.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"training/KAN_7/model\"\n",
    "\n",
    "output_path = f'matlab/only_damp/matlab_evaluations/predictions_csv_files/KAN_7'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "model_files = glob.glob(os.path.join(model_path, \"model_*.pt\"))\n",
    "if model_files:\n",
    "# Extract numbers and find the highest one\n",
    "    latest_model = max(model_files, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "    print(\"Evaluating model in:\", latest_model)\n",
    "else:\n",
    "    print(\"No model files found in the directory.\")\n",
    "\n",
    "#model_path = latest_model\n",
    "\n",
    "loaded_model = torch.load(latest_model)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Process in batches\n",
    "with torch.no_grad():\n",
    "    for i in range(0, n_samples):\n",
    "        # end_idx = min(i + batch_size, n_samples)  # Ensure we don't go past the array end\n",
    "        batch_inputs = inputs[i]\n",
    "        batch_outputs = loaded_model(batch_inputs)\n",
    "        pred = batch_outputs.cpu().numpy()\n",
    "        pred_denorm = (pred*(u_max - u_min)) + u_min\n",
    "        predictions[i] = pred_denorm # Only take the needed values\n",
    "    \n",
    "        print(pred_denorm)\n",
    "\n",
    "# Formatting predictions for matlab use\n",
    "reshaped_predictions = predictions.reshape(-1, 1917).T\n",
    "np.savetxt(output_path + '/predictions.csv', reshaped_predictions, \n",
    "    delimiter=',', fmt='%.6f')  \n",
    "\n",
    "print(f\"Predictions completed and saved to {output_path}\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(df.head())\n",
    "\n",
    "# Print statistics about the predictions\n",
    "print(\"\\nPrediction statistics:\")\n",
    "print(f\"Mean: {predictions.mean():.4f}\")\n",
    "print(f\"Std: {predictions.std():.4f}\")\n",
    "print(f\"Min: {predictions.min():.4f}\")\n",
    "print(f\"Max: {predictions.max():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
